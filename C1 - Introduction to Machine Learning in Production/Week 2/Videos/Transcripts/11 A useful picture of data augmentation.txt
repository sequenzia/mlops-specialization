There's a picture, a conceptual picture
that I found useful for thinking about data augmentation and how this can help
the performance of a learning algorithm. Let me share this picture of you since I
think you find it useful to when trying to decide whether to use data augmentation. Take speech recognition. There could be many different types of
noise in speech input such as car noise, play noise, train noise,
machine noise, cafe noise or library noise, which isn't that loud or
food court noise. Maybe these types of noises are more
similar to each other because they're all mechanical types of noise and these types
of noise maybe a little bit more similar to each other with mainly people talking
and interacting with each other. So let me share of your picture that I
keep in mind when I'm planning out my activities on getting more data
through data augmentation or through actual data collection
of any of these types of data. In this diagram, the vertical axis
represents performance, say accuracy. And on the horizontal axis, and this is a conceptual kind of
a thought experiment type of access. I'm going to represent
the space of possible inputs. So for
example there speech with car noise and plane noise and
train noise sound a bit like car noise. So they're quite similar and
machine noise a little bit further away, by machine noise, I'm picturing
the sounds of a washing machine or a very loud air conditioners. Then you may have speech with cafe noise,
library noise or food court ,and those are maybe
more similar to each other. Then to these types of mechanical noise. Your system will have different levels
of performance on these different types of input. Let's say the performance is this for
data of play noise, that of car noise,
train noise, machine noise. And it does worse on data with library
noise, cafe noise, food court noise. And so I think of their as being a curve. Or maybe think of this like a one
dimensional piece of rubber band or like a rubber sheet that shows
how accurate your speech system is as a function of
the type of input it gets. A human will have some other
level of performance on these different types of data. So maybe a human is a bit better,
will play noise bit better in car noise, and so on and maybe they are much
better then your algorithm on library noise, cafe noise and
food court noise. So the human level performance is
represented via some other curve. And let me just label this as
the current models performance in blue. So this gap represents an opportunity for
improvement. Now, what happens if you
use data augmentation or maybe not data augmentation but
go out to a bunch of actual cafes, to collect a lot more data with
cafe noise in the background. What you'll do is, you'll take this
point imagine grabbing a hold of this blue rubber bands or this rubber sheet,
and pulling it upward like so. That's what you're doing if you collect or somehow gets more data with cafe noise and
add that your training set, you're pulling up the performance of
the algorithm on inputs with cafe noise. And what that will tend to do, is pull up this rubber sheet in
the adjacent region as well. So if performance on cafe noise goes up,
probably performance on the nearby points will go up too and
performance on far away. Points may or may not go up as much. It turns out that for
unstructured data problems, pulling up one piece of this
rubber sheet is unlikely to cause a different piece of the rubber
sheet to dip down really far below. Instead, pulling up one point causes
nearby points to be pulled up quite a lot and far away points may be pulled up
a little bit, or if you're lucky, maybe more than a little bit. But when I'm planning how to improve
my learning algorithm's performance and where I hope to get it to, and getting more data in those places to
iteratively pull up with those pieces or those parts of the rubber sheet to get
them closer to human level performance. And when you pull up
part of the rubber sheet, the location of the biggest gap
may shift to somewhere else. And error analysis will tell you what is
the location of this new biggest gap, that may then be worth your effort,
to collect more data on and therefore to try to pull
up one piece at a time. And this turns out to be a pretty
efficient way to decide where on the blue rubber sheet to pull up next to
try to get performance closer to, say human level performance. I hope this analogy of a rubber band or
rubber sheet and repeatedly pulling up a point on this rubber sheet will help
you predict the effects of collecting more data that's associated with
a specific category or a specific tag. How do you get more of this data? Let's take a look at how you can
perform data augmentation and some best practices doing so
in the next video.