Some machine learning tasks are trying to
predict an inherently ambiguous output and Human Level Performance can establish
a useful baseline of performance as a reference. But Human Level Performance
is also sometimes misuse. Let's take a look. One of the most important users of
measuring Human Level Performance or HLP is to estimate based error or
irreducible error. Especially on unstructured data tasks in
order to help with their analysis and prioritization and
just establish what might be possible. Take a visual inspection tasks. This may have happened to you before, but I have gotten requests from
business owners saying, hey Andrew, can you please build a system that's
99% accurate or maybe 99.9% accurate. So one way to establish what might be
possible would be to take a data set and look at the Ground Truth Data. Say you have six examples where
the Ground Truth Label is these, and then to answer human inspector to
label the same data blinded to the Ground Truth Label of course and
see what they come up with. And if they come up with these you
would say this inspector agreed to the ground truth on four other six
examples and disagreed on two out of six. And so Human Level Performance is 66.7%. And so this would let you go back
to the business owner and say look, even your inspector is
only 66.7% accuracy. How can you expect me to Get 99% accuracy? So HLP is useful for establishing a baseline in terms
of what might be possible. There's one question
that is often not asked, which is what exactly is
this Ground Truth Label? Because rather than just
measuring how well we can do compared to some Ground Truth Label, which was probably written
by some other human. Are we really measuring what is
possible or are we just measuring how well two different people happen
to agree with each other? When the Ground Truth Label is
itself determined by a person. There's a very different approach to
thinking about Human Level Performance which I want to share of you in this and
the next video. Beyond this purpose of estimating Bayes
error and establishing what's possible using that to help with their analysis and
prioritization. Here are some other users
of Human Level Performance. In academia, HLP is often used
as a respectable benchmark. And so when you establish that
people are only 92% accurate or some of the number on a speech
recognition data set. And if you can beat
human level performance, then that establishes then that helps
you to quote proof that you're learning algorithm is doing something hard and
helps get the paper published. I'm not saying this is a great use of HLP,
but in academia showing you
can beat HLP maybe for the first time has been a tried and
true formula for establishing the academic
significance of a piece of work and helps with getting something published. We discussed briefly on the last slide
what to do if a business of product owner asked for 99% accuracy and
if you think that's unrealistic, then measuring HLP may help you to
establish a more reasonable target. That's one of the use of HLP
that you might hear about. Do not be cautious about which is,
I've seen many projects with the machine learning team,
wants to use HLP or beating HLP. To prove that the Machine Learning System
is superior to the human is doing the job. And as tempting as it is to go to
someone and says look, I've proved that my machinery system is more accurate
than humans inspecting the phones or the radiologist reading X-rays or
something. And now that I've mathematically proved
the superiority of my learning album, you have to use it right? I know the logic of that is tempting, but as a practical matter,
this approach rarely works. And you also saw last week
that businesses need systems that do more than just doing well
on average test set accuracy. So if you ever find
yourself in this situation, I would urge you to just use this
type of logic with caution or maybe even more preferably just
don't use these arguments. I've usually found other arguments
than this to be more effective that working with the business to see if they
should adopt a Machine Learning System. The problem with beating
Human Level Performance as proof of machine learning
superiority is multi fold. Beyond the fact that most
applications require more than just high average tested accuracy,
one of the problems with this metric is that it sometimes gives
a learning algorithm an unfair advantage when labeling
instructions are inconsistent. Let me show you what I mean. If you have inconsistent
labeling instructions so that when an audio clip
says nearest gas station, let's say 70% of labelers,
uses label convention and 30 percent of labelers
uses label convention. Neither one is the superiors transcript
to the other both seemed completely fine. But just by luck of the draw,
70% of labelers choose the first one, 30% choose the second one. So if the ground truth is
established by a labelers, maybe just a laborer with a slightly
bigger title, but really by one labelers. Then the chance that two
random labeler will agree will be 0.7 squared plus 0.3 squares,
which is 0.58. So if you had two labelers
use the first convention, there's a 0.7 square chance of that. Or if both of your random labelers
use the second convention, there's a 0.3 square chance of that. Then the two of them will agree. So the chances to labelers agreeing 0.58. And in the usual way of measuring
Human Level Performance, you will conclude that
Human Level Performance is 0.58. But what you're really measuring is the
chance of two random labelers agreeing. This is where the machine learning
our room has an unfair advantage. I think either of these labeling
conventions is completely fine. But the learning algorithm is a little
bit better at gathering statistics of how often ellipses versus commas are
used in such a context than the learning algorithm may be able to always
use the first labeling convention. Because it knows that statistically, it has a 70% chance of getting it right
if it uses ellipses or dot dot dot. So a learning algorithm will agree
with humans 70% of the time, just by choosing the first
lebeling convention. But this 12% improvement in performance, whereas Human Level Performance is 58% and your learning algorithm
is 12% better is 0.70. This 12 better performance is
not actually important for anything between these two equally good, slightly arbitrary choices. The learning algorithm just
consistently picks the first one so it gains what seems like a 12%
advantage on this type of query, but it's not actually outperforming any human
in any way that a user would care about. And one side effect of this is that, if you're speech recognition tool
has multiple types of audio. For some, there's this dot dot dot or
ellipses versus common ambiguity and learning album does 12% better on this. If you're learning algorithm makes some
more significant errors on other types of input audio, then when its performance
where it actually does worse could be averaged out by queries like these where
kind of fake looks like it's doing better. And this will therefore mask or hide
the fact that you're learning algorithm is actually creating worse
transcripts than humans actually are. And what this means is that
a machine learning system can look like it's doing better than HLP. But actually be producing worse
transcripts than people because it's just doing better on this type of problem
which is not important to do better on while potentially actually doing worse
on some other types of input audio. Given these problems with Human Level
Performance, what are we supposed to do? Measuring Human Level Performance
is useful for establishing a baseline using that to
drive error analysis and prioritization. But using it to benchmark machines and humans sometimes runs into
problematic cases like this. I found that when my goal is
to build a useful application, not publish a paper, you publish a paper, let's prove we can outperform
people that helps published paper. But found that when my goal is to build
a useful application rather than trying to beat Human Level Performance, I found it's often useful to instead
try to raise Human Level Performance because we raise Human Level Performance
by improving label consistency and that ultimately results in better
learning outcomes performance as well. Let's take a deeper look
at this in the next video