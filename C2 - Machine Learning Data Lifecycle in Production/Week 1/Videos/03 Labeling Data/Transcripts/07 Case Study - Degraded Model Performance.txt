Welcome back. The only constant in
the universe is change. That quote is actually attributed to
Heraclitus of a thesis in 500 BC. And I think it's fairly safe to
say that it's still true today and it affects production amount. So for example if you had trained a model
a few years ago to recognize what a book looks like,
it might have looked like this. If you train a model today, you'd also
want to include books that look like this. Let's find out more now. To illustrate some of the issues with
labeled data in performance settings, let's take a look at a case study. So imagine that you're
an online retailer and you're selling shoes and
you have a model that predicts click through rates which helps you to
decide how much inventory to order. And suddenly the AUC and
prediction accuracy have dropped not on everything but
on a particular part of your inventory. Men's dress shoes. Okay. Why?
You trained your model? You did fairly well in your metrics and
so forth. Why is it different? What changed? Why does your model not predict
men's dress shoes well now? And perhaps more importantly, how do
you even know that you have a problem? Your models still running? It's still giving predictions. You're still ordering inventory. How do you know that the orders
that you're making and the predictions that your model is giving
you are not as good as they used to be? Well, unfortunately,
if you don't put good practices into place in the production setting,
you're probably going to find out either when you order way too many shoes or
not enough shoes. And that's not a situation that
you want to be in in a business. This is going to cost you money. So you need to think about how you're
going to detect problems like that early. And what the possible causes are so
that you can look for those and monitor your system. And then try to have methods systems
in place to deal with those problems when they happen because they
probably will happen at some point. But what kinds of problems? Well, there's different kinds and they tend to fall into
two different categories. There are slow problems. So for example, your data will drift
over time as the world changes and seasons pass and you have holidays and competitors enter or change what have you. And then you have fast problems that
are really part of your system. So you have a sensor that goes bad or
you have a software update that gets applied and
suddenly things are wonky. So you need to really be monitoring
your system well and looking for both of those problems and
thinking about remediation in both cases. For gradual problems, they tend to
fall into two groups really, but they're interrelated too so it's not
like there's a hard line between them. Trend and seasonality for example,
especially in time series you will have trends and you will have seasonality
in most cases and you could argue about whether that's really a change
in data or a change in the world. Same thing with the distribution
of the features. Again, it's something that
you see in your data. And the relative importance of features
can change too as the relative importance changes, if you haven't retrained
your model accuracy starts to decay. The world also changes constantly. And in production settings that
has to become part of the systems that you design and
the processes that you have in place. Things like, well,
if we're working in retail and we're just looking at an example
with shoes, styles change. So, maybe last year black shoes
were really fashionable for men's dress shoes and
now it's brown shoes or what have you. The scope and the processes change. So your understanding
of those processes and how they happen in the world
will affect how your model views the results
of those processes. Competitors change and
your business also changes. So you may take on new products, you may end of life other products
you may have new competitors, you may expand into other geography
ease or you may move out of geography, ease prices from suppliers change,
prices on the open market, change all of that affects how your
model needs to adapt to the world. And this tends to be very domain specific,
but in general, in nearly all domains, changes in
the world affect your model performance. So for sudden problems, there's things
that you're probably familiar with. So data collection problems,
things like a bad sensor or bad camera, the log data suddenly changes and
you have a different format or the logs themselves are may be rotated
differently, you can have a sensor or a camera that doesn't really change,
but it moves. Maybe it gets bumped or maybe someone
decided it should be in a different spot. I personally have seen that
happen where we had cameras that someone decided that they should be
moved and didn't tell us about that. [LAUGH]. Systems problems. So you're going to have software updates
all the time and if they change something significant that you weren't aware of,
that can be a real problem. Network connectivity. No, no, the network never goes down,
does it? Well, maybe sometimes it does. Systems too. Whole systems can go down. So be aware of that. [LAUGH]. And bad credentials, you sign
credentials and often they time out or something changes about them,
all those things can cause a sudden problem that all of a sudden it's a fire
drill and you need to deal with it. So part of this is really trying
to understand your model and how it's sensitive to different
changes in the world. A big issue here is that miss predictions
don't have uniform cost to your business. Some miss predictions will have very
little effect on your business. Other miss predictions
could have huge effects. So understanding that and
really as you're monitoring things, looking for things that have
larger impacts is important. The data you have as you collect data is
rarely the data that you wish you had. So I've personally seen cases where
we were using sensor data from wifi devices and it was not great data. It was really noisy and
but it was all we had. It was all we could have. So we had to work with what we had. The model objective is
almost always a proxy for what you're really trying to get to. In many cases, sometimes you can design
a model and you have the data to design a model for exactly the thing
that you're trying to attack. But often, as in the case of
the shoes that we just looked at, we were predicting click
through rates as a proxy for deciding how much inventory to order. Some percentage of your customers
will have a bad experience. You want that percentage to be as small
as possible and as much as possible, you want to understand which
customers those are going to be, so that you can try to design
ways to mitigate that and improve the situation for
all of your customers. But the bottom line here that you will
deal with constantly is that the real world does not stand still. The one constant in the world is change.