So now that you've seen model serving
from a high level, let's dig into some of the architecture is a little more deeply,
starting with TensorFlow Serving. In week 1, you had a chance to experiment
with the basics of TF serving, which is a flexible, high performance serving
system for machine learning models. It provides out of the box integration
with tensorflow models and it can also be extended to
serve other types of model. So let's take a look at the architecture
of this serving system and some important features that
I'd like to call out our that it provides both batch and
real time inference. So you can either get a bunch
of inferences at the same time, which is useful if you're building
something like a recommendation engine. That requires a lot of predictions or real time inference if you want to
answer to a single task back quickly. And this is useful for for
example, an image classification. Multi model serving is also available and
this allows you to have multiple models for the same task and
the server chooses between them. This could be useful for example, for a b
testing audience segmentation and more. And it also provides
remote procedure calls or traditional rest endpoints on
which you can call your server. The high level architecture for
tensorflow serving looks like this. It's built around the core
idea of a servable, which is the central
abstraction in TF serving. These are the underlying objects that
clients used to perform computation. For example, inference or lookups. There can be any kind of type or interface
and this makes them very flexible. A typical servable is
a tensorflow saved model but it could also be something like
a look up table for an embedding. The loader manages a survivals lifecycle. The loader API enables common
infrastructure independent from specific learning algorithms, data or
whatever product use cases were involved. Specifically loaders standardized the API
is for loading and unloading a servable. Together these produce
aspired versions and these represent the set of servable
versions that should be loaded and ready. Sources communicate this set of
servable versions for a single servable stream at a time when a source gives a new
list of aspired versions to the manager. It supersedes the previous list for
that servable stream. The manager unloads any previously
loaded versions that no longer appear in the list. The Manager then handles the full life
cycle of the survivals, including loading the survivals serving the survivals and
of course unloading the survivals. The managers will listen
to the sources and will track all of the versions
according to a version policy and the servable handle provides
the exterior interface to the client. There's a lot of pieces here. So let's look at an example
of how this would work. So let's take this as an example,
say a source represents a tensorflow graph with
frequently updated model weights. The weights are stored in a file and disk. The source detects a new
version of the model weights. It creates a loader that contains
a pointer to the model data on disk. The source notifies the dynamic
manager of the aspired version. The dynamic manager applies
the version policy and decides to load the new version. The dynamic manager tells
the loader that is enough memory. The loader instantiates
the tensorflow graph as a servable with these new weights. A client requests a handle to
the latest version of the model and the dynamic manager returns a handle
to the new version of the servable. You can then run inference using that
servable and this is what you would have seen last week when you built
the fashion MNIST model example.